apiVersion: batch/v1
kind: Job
metadata:
  name:  yolov5-test-job
spec:
  # 失败后重试次数，设为0表示不重试，可以根据需要调整
  backoffLimit: 2
  template:
    spec:
      containers:
      - name: gpu-container
        image: timttu/yolov5-nrp:v2
        command: ["/bin/bash", "-c"]
        args: [
            "set -e && \
            git config --global credential.helper store && \
            echo \"https://oauth2:${GIT_ACCESS_TOKEN}@github.com\" > ~/.git-credentials && \
            cd /pers_vol && \
            if [ ! -d yolov5-nrp ]; then \
              echo 'Cloning repository...' && \
              git clone https://github.com/timtutu2/yolov5-nrp.git yolov5-nrp ; \
             else \
               echo 'Repository exists, discarding local changes and pulling latest...' && \
               cd yolov5-nrp && git fetch origin && git reset --hard origin/lab ; \
             fi && \
            cd /pers_vol/yolov5-nrp && \
            mkdir -p /pers_vol/tim/finetune_test/logs && \
            echo 'Starting training with pre-processed data...' && \
            python train.py --data dataset/car/data.yaml --weights yolov5n.pt --epochs 100 --batch-size 16 --img 640 --device 0 \
                > /pers_vol/tim/yolov5-nrp/logs/$(date +%Y-%m-%d_%H-%M-%S)-yolov5-nrp-train.log 2>&1"
        ]
        env:
        - name: WANDB_API_KEY
          valueFrom:
            secretKeyRef:
              name: wandb-tim-secret
              key: api_key
        - name: GIT_ACCESS_TOKEN
          valueFrom:
            secretKeyRef:
              name: tim-github-token
              key: GIT_ACCESS_TOKEN
        volumeMounts:
        - mountPath: /pers_vol
          name: tim-vol
        - mountPath: /workspace
          name: tim-vol
          subPath: multimodal-material-estimation
        - mountPath: /MultiModalMaterialEstimation_finetune
          name: tim-vol
          subPath: MultiModalMaterialEstimation_finetune
        - mountPath: /dev/shm
          name: dshm
        resources:
          limits:
            nvidia.com/gpu: "3"
            memory: "48G"
            cpu: "4"
          requests:
            nvidia.com/gpu: "3"
            memory: "42G"  
            cpu: "4"
      restartPolicy: Never
      # Force scheduling to specific node
      # nodeSelector:
      #   kubernetes.io/hostname: ry-gpu-11.sdsc.optiputer.net
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          # Empirically determined nodes with good network to download large docker images
          - weight: 100
            preference:
              matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - "ry-gpu-01.sdsc.optiputer.net"
                - "ry-gpu-02.sdsc.optiputer.net"
                - "ry-gpu-03.sdsc.optiputer.net"
                - "ry-gpu-04.sdsc.optiputer.net"
                - "ry-gpu-05.sdsc.optiputer.net"
                - "ry-gpu-06.sdsc.optiputer.net"
                - "ry-gpu-07.sdsc.optiputer.net"
                - "ry-gpu-08.sdsc.optiputer.net"
                - "ry-gpu-09.sdsc.optiputer.net"
                - "ry-gpu-10.sdsc.optiputer.net"
                - "ry-gpu-11.sdsc.optiputer.net"
                - "ry-gpu-12.sdsc.optiputer.net"
                - "ry-gpu-13.sdsc.optiputer.net"
                - "ry-gpu-14.sdsc.optiputer.net"
                - "ry-gpu-15.sdsc.optiputer.net"
                - "ry-gpu-16.sdsc.optiputer.net"
                - "k8s-3090-01.calit2.optiputer.net"
                - "k8s-4090-01.calit2.optiputer.net"
                - "k8s-4090-02.calit2.optiputer.net"
          - weight: 50
            preference:
              matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - "k8s-haosu-02.sdsc.optiputer.net"
                - "k8s-haosu-03.sdsc.optiputer.net"
                - "k8s-haosu-04.sdsc.optiputer.net"
                - "k8s-haosu-05.sdsc.optiputer.net"
                - "k8s-haosu-06.sdsc.optiputer.net"
                - "k8s-haosu-07.sdsc.optiputer.net"
                - "k8s-haosu-08.sdsc.optiputer.net"
                - "k8s-haosu-09.sdsc.optiputer.net"
                - "k8s-haosu-10.sdsc.optiputer.net"
                - "k8s-haosu-11.sdsc.optiputer.net"
                - "k8s-haosu-12.sdsc.optiputer.net"
                - "k8s-haosu-13.sdsc.optiputer.net"
                - "k8s-haosu-14.sdsc.optiputer.net"
                - "k8s-haosu-15.sdsc.optiputer.net"
                - "k8s-haosu-16.sdsc.optiputer.net"
                - "k8s-haosu-17.sdsc.optiputer.net"
                - "k8s-haosu-18.sdsc.optiputer.net"
                - "k8s-haosu-19.sdsc.optiputer.net"
                - "k8s-haosu-20.sdsc.optiputer.net"
                - "k8s-haosu-21.sdsc.optiputer.net"
                - "k8s-haosu-22.sdsc.optiputer.net"
                - "k8s-haosu-23.sdsc.optiputer.net"
          - weight: 80
            preference:
              matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - "NVIDIA-A100-80GB-PCIe"
                - "NVIDIA-A100-SXM4-80GB"
                - "NVIDIA-A100-80GB-PCIe-MIG-1g.10gb"
                - "NVIDIA-A100-PCIE-40GB"
                - "NVIDIA-RTX-A6000"
                - "NVIDIA-RTX-A5000"
                - "NVIDIA-GeForce-RTX-4090"
                - "NVIDIA-GeForce-RTX-4080"
                - "NVIDIA-GeForce-RTX-3090-Ti"
                - "NVIDIA-GeForce-RTX-3090"
                - "NVIDIA-GeForce-RTX-3080-Ti"
                - "NVIDIA-GeForce-RTX-3080"
          - weight: 60
            preference:
              matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - "NVIDIA-A40"
                - "Tesla-V100-SXM2-32GB"
                - "Tesla-V100-PCIE-16GB"
          - weight: 50
            preference:
              matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - "NVIDIA-TITAN-RTX"
                - "NVIDIA-GeForce-RTX-2080-Ti"
                - "NVIDIA-TITAN-Xp"
                - "NVIDIA-L40"
                - "NVIDIA-A10"
      volumes:
        - name: tim-vol
          persistentVolumeClaim:
            claimName: tim-vol
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi

